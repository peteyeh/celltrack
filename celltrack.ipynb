{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/peteyeh/celltrack/HEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from math import hypot\n",
    "from scipy.stats import trim_mean\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from displaytools import *\n",
    "from improcessing import *\n",
    "\n",
    "plt.rcParams.update({'font.size': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a list of (x, y) coordinates corresponding to points in the cluster.\n",
    "# This cluster is presumed to be INaccurate, so we trim the outliers.\n",
    "def compute_approx_centroid(cluster):\n",
    "    y = int(trim_mean(cluster[:, 0], 0.25))\n",
    "    x = int(trim_mean(cluster[:, 1], 0.25))\n",
    "    return x, y\n",
    "\n",
    "# Takes a list of (x, y) coordinates corresponding to points in the cluster.\n",
    "# This cluster is presumed to be accurate, so we use all values given.\n",
    "# Output:\n",
    "#  - x, y: the centroid\n",
    "#  - box_x: x distance from the centroid for the bounding box\n",
    "#  - box_y: y distance from the centroid for the bounding box\n",
    "def compute_centroid_and_box(cluster):\n",
    "    x = int(np.mean(cluster[:, 1]))\n",
    "    size_x = np.max(cluster[:, 1]) - np.min(cluster[:, 1])\n",
    "    box_x = int(1.2*size_x)\n",
    "\n",
    "    y = int(np.mean(cluster[:, 0]))\n",
    "    size_y = np.max(cluster[:, 0]) - np.min(cluster[:, 0])\n",
    "    box_y = int(1.2*size_y)\n",
    "    \n",
    "    return x, y, max(15, box_x), max(15, box_y)\n",
    "\n",
    "def compute_distance(x1, y1, x2, y2):\n",
    "    return hypot(x2-x1, y2-y1)\n",
    "\n",
    "# Returns True if both cells are within each other's bounding boxes.\n",
    "def is_overlapping(cell1, cell2):\n",
    "    x1, y1, box_x1, box_y1, merge_events, distance_travelled = cell1\n",
    "    x2, y2, box_x2, box_y2, merge_events, distance_travelled = cell2\n",
    "    return x1 > x2-box_x2 and x1 < x2+box_x2 and \\\n",
    "           y1 > y2-box_y2 and y1 < y2+box_y2 and \\\n",
    "           x2 > x1-box_x1 and x2 < x1+box_x1 and \\\n",
    "           y2 > y1-box_y1 and y2 < y1+box_y1\n",
    "\n",
    "# Overlap centroids if they are within each other's bounding boxes.\n",
    "# Note that this modifies cells in-place.\n",
    "def dedup_centroids(image, cells):\n",
    "    image = apply_impipeline(image)\n",
    "    num_cells = len(cells)\n",
    "    cell_overlap = np.identity(num_cells)\n",
    "\n",
    "    # Establish overlapping cells\n",
    "    for i in range(num_cells):\n",
    "        for j in range(i+1, num_cells):\n",
    "            if is_overlapping(cells[i], cells[j]):\n",
    "                cell_overlap[i][j] = 1\n",
    "                cell_overlap[j][i] = 1\n",
    "    \n",
    "    for i in range(num_cells):\n",
    "        if sum(cell_overlap[i]) == 1:  # cell is alone\n",
    "            continue\n",
    "        else:\n",
    "            c = np.argwhere(cell_overlap[i])\n",
    "            cf = c.flatten()\n",
    "            # Do cool tricks here; establishes if all cells overlapping with\n",
    "            # cells[i] overlap with each other\n",
    "            if np.sum(cell_overlap[cf, c]) == sum(cell_overlap[i])**2 and \\\n",
    "               np.sum(np.delete(cell_overlap[cf], cf, axis=1)) == 0 and \\\n",
    "               np.sum(np.delete(cell_overlap[:, cf], cf, axis=0)) == 0:\n",
    "                # Remove cells that have been merged away\n",
    "                ct = np.array(list(filter(lambda a: cells[a][4] != -1, cf)))\n",
    "                # Nothing left to merge\n",
    "                if len(ct) <= 1:\n",
    "                    continue\n",
    "                # Establish new centroid and bounding box\n",
    "                new_x = int(np.mean(cells[ct][:,0]))\n",
    "                new_y = int(np.mean(cells[ct][:,1]))\n",
    "                new_box_x = max(new_x - min(cells[ct][:,0] - cells[ct][:,2]),\n",
    "                                max(cells[ct][:,0] + cells[ct][:,2]) - new_x)\n",
    "                new_box_y = max(new_y - min(cells[ct][:,1] - cells[ct][:,3]),\n",
    "                                max(cells[ct][:,1] + cells[ct][:,3]) - new_y)\n",
    "                new_box = get_box(image, new_x, new_y, new_box_x, new_box_y)\n",
    "                new_box_primary_components = \\\n",
    "                    remove_secondary_components(new_box, threshold=0.2)\n",
    "                # Only merge if it looks like there is only one cell in the new box\n",
    "                if get_num_components(new_box_primary_components) == 1:\n",
    "                    # Establish the index of the cell to keep after the merge:\n",
    "                    #  - Try to keep the cell with the most merge events\n",
    "                    #  - Failing that, choose the largest cell\n",
    "                    most_merges = ct[np.where(cells[ct][:,4]==cells[ct][:,4].max())[0]]\n",
    "                    if len(most_merges) == 1:\n",
    "                        primary_cell = most_merges[0]\n",
    "                    else:\n",
    "                        cell_areas = np.prod(cells[most_merges][:,2:4], axis=1)\n",
    "                        primary_cell = most_merges[np.argmax(cell_areas)]\n",
    "#                         primary_cell = most_merges[np.argmax(cells[most_merges][:,5])]\n",
    "                    cells[primary_cell][0] = new_x\n",
    "                    cells[primary_cell][1] = new_y\n",
    "                    cells[primary_cell][2] = new_box_x\n",
    "                    cells[primary_cell][3] = new_box_y\n",
    "                    cells[primary_cell][4] += len(ct)-1\n",
    "                    for ci in ct:\n",
    "                        if ci != primary_cell:\n",
    "                            cells[ci][4] = -1\n",
    "                            cells[ci][5] = -1\n",
    "                    cell_overlap[cf, c] = np.identity(len(cf))\n",
    "\n",
    "# Using new_image, update the centroids in cells. Note that this modifies\n",
    "# cells in-place.\n",
    "def update_tracking(new_image, cells):\n",
    "    new_image = apply_impipeline(new_image)\n",
    "    \n",
    "    for i in range(len(cells)):\n",
    "        x, y, box_x, box_y, merge_events, distance_travelled = cells[i]\n",
    "        \n",
    "        if merge_events == -1:\n",
    "            continue\n",
    "        \n",
    "        box = get_box(new_image, x, y, box_x, box_y)\n",
    "\n",
    "        if len(box) == 0:\n",
    "            cells[i][4] = -1\n",
    "            cells[i][5] = -1\n",
    "            continue\n",
    "\n",
    "        filtered = remove_secondary_components(box)\n",
    "        num_components = get_num_components(filtered)\n",
    "        \n",
    "        # Need to ensure cell is inside the box\n",
    "        if num_components == 0:\n",
    "            cells[i][4] = -1\n",
    "            cells[i][5] = -1\n",
    "            continue\n",
    "\n",
    "        cluster = np.argwhere(filtered)\n",
    "        if num_components == 1:\n",
    "            sub_x, sub_y, new_box_x, new_box_y = compute_centroid_and_box(cluster)\n",
    "            cells[i][2] = new_box_x\n",
    "            cells[i][3] = new_box_y\n",
    "        else:\n",
    "            sub_x, sub_y = compute_approx_centroid(cluster)\n",
    "        new_x = max(x-box_x, 0) + sub_x\n",
    "        new_y = max(y-box_y, 0) + sub_y\n",
    "        cells[i][0] = new_x\n",
    "        cells[i][1] = new_y\n",
    "        cells[i][5] = distance_travelled + compute_distance(x, y, new_x, new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read initial image and find centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: (832, 1128)\n"
     ]
    }
   ],
   "source": [
    "rfp = cv2.imreadmulti('source_images/RFP-1.tif')[1]\n",
    "\n",
    "initial_image = rfp[0]\n",
    "\n",
    "# 0 is a throwaway param, Otsu will determine\n",
    "threshold, binarized = \\\n",
    "    cv2.threshold(initial_image, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "initial_binarized = np.uint8(initial_image < threshold)\n",
    "\n",
    "coordinate_bounds = initial_image.shape\n",
    "print(\"Image dimensions: \" + str(coordinate_bounds))\n",
    "\n",
    "# display_image_array([initial_image, initial_binarized], columns=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking 180 cells\n"
     ]
    }
   ],
   "source": [
    "cell_points = np.argwhere(1-initial_binarized)\n",
    "clustering = DBSCAN(eps=6, min_samples=10).fit(cell_points)\n",
    "labels = clustering.labels_\n",
    "\n",
    "# Store cells as [[centroid, box_x, box_y], ...]\n",
    "cells = []\n",
    "# Track cell metadata\n",
    "merge_events = 0\n",
    "distance_travelled = 0\n",
    "\n",
    "# Note that clustering.labels_ includes -1, which are noisy samples.\n",
    "# Thus, enforce starting at 0 rather than min(labels).\n",
    "for i in range(0, max(labels)+1):\n",
    "    indices = np.where(labels == i)\n",
    "    cluster = cell_points[indices]\n",
    "    x, y, box_x, box_y = compute_centroid_and_box(cluster)\n",
    "    cells += [[x, y, box_x, box_y, merge_events, distance_travelled],]\n",
    "    \n",
    "cells = np.array(cells)\n",
    "\n",
    "print(\"Tracking %i cells\" % len(cells))\n",
    "display_centroids(initial_image, cells, save_name='0')\n",
    "\n",
    "gif_buffer = [add_centroids_and_boxes_to_image(initial_image, cells, gif_mode=True)]\n",
    "# display_centroids(initial_binarized, cells, mode='matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](saved_images/0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept for LoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = rfp[1]\n",
    "# x, y, box_x, box_y, merge_events = cells[2]\n",
    "# box = get_box(image, x, y, box_x, box_y)\n",
    "\n",
    "# # LoG\n",
    "# blurred = cv2.GaussianBlur(np.float64(box), (3,3), 0)\n",
    "# filtered = cv2.Laplacian(np.float64(blurred), cv2.CV_64F)\n",
    "# edges = (filtered == 0).astype(int)  # need to threshold this\n",
    "\n",
    "# display_image_array([box, blurred, filtered, edges], columns=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept for Image Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_canny = apply_canny(rfp[1])\n",
    "# im_pipeline = apply_impipeline(rfp[1])\n",
    "# for i in range(10): # len(cells)):\n",
    "#     x, y, box_x, box_y, merge_events, distance_travelled = cells[i]\n",
    "#     box_canny = get_box(im_canny, x, y, box_x, box_y)\n",
    "#     box_pipeline= get_box(im_pipeline, x, y, box_x, box_y)\n",
    "#     display_image_array([box_canny, remove_secondary_components(box_pipeline)],\n",
    "#                         columns=2, dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sub_images(image, cells):\n",
    "#     boxes = []\n",
    "#     for i in range(len(cells)):\n",
    "#         x, y, box_x, box_y, merge_events, distance_travelled = cells[i]\n",
    "#         box = get_box(image, x, y, box_x, box_y)\n",
    "#         boxes += [box,]\n",
    "#     return boxes\n",
    "\n",
    "# raw_boxes = get_sub_images(rfp[1], cells)\n",
    "# processed_boxes = get_sub_images(apply_impipeline(rfp[1]), cells)\n",
    "# display_image_array(raw_boxes)\n",
    "# display_image_array([remove_secondary_components(box) for box in processed_boxes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_distance = np.zeros((len(cells), len(rfp)))\n",
    "merge_log = np.zeros((len(cells), len(rfp)))\n",
    "\n",
    "for i in range(1, len(rfp)):\n",
    "    image = rfp[i]\n",
    "    update_tracking(image, cells)\n",
    "    dedup_centroids(image, cells)\n",
    "    cumulative_distance[:,i] = cells[:,5]\n",
    "    merge_log[:,i] = cells[:,4]\n",
    "    display_centroids(image, cells, save_name=str(i))\n",
    "    gif_buffer.append(add_centroids_and_boxes_to_image(image, cells, gif_mode=True))\n",
    "\n",
    "imageio.mimsave('centroids.gif', gif_buffer, duration=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](centroids.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot cumulative distance travelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 8})\n",
    "plt.figure(dpi=240)\n",
    "plt.title(\"Cumulative Distance Travelled\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Pixels\")\n",
    "plt.xlim([0, len(rfp)])\n",
    "plt.ylim([0, np.max(cumulative_distance)+10])\n",
    "\n",
    "merge_log_shifted = \\\n",
    "    np.concatenate((np.zeros((len(merge_log), 1)), merge_log[:,:-1]), axis=1)\n",
    "merge_events = ((merge_log - merge_log_shifted) > 0)\n",
    "\n",
    "for i in range(len(cumulative_distance)):\n",
    "    cd = cumulative_distance[i]\n",
    "    ml = merge_log[i]\n",
    "    me = merge_events[i]\n",
    "    \n",
    "    # Plot cumulative distance\n",
    "    lost_frame = len(cd)\n",
    "    if -1 in cd:\n",
    "        lost_frame = np.where(cd==-1)[0][0]\n",
    "        cd = cd[:lost_frame]\n",
    "        ml = ml[:lost_frame]\n",
    "    num_merges = ml[-1]\n",
    "    c, l = 'r', 0.1\n",
    "    if num_merges >= 3:\n",
    "        c, l = 'g', 0.7\n",
    "    elif num_merges >= 1:\n",
    "        c, l = 'b', 0.3\n",
    "    plt.plot(cd, color=c, linewidth=l)\n",
    "    \n",
    "    # Plot merge events\n",
    "    x = np.argwhere(me==True).flatten()\n",
    "    y = np.array(cd[x])\n",
    "    plt.scatter(x, y, s=15, c='k', marker='|', linewidth=0.7)\n",
    "plt.savefig('distance.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](distance.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
